<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title></title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <meta property="og:title" content="">
        <meta property="og:type" content="">
        <meta property="og:url" content="">
        <meta property="og:image" content="">

        <link rel="manifest" href="site.webmanifest">
        <link rel="apple-touch-icon" href="icon.png">
        <!-- Place favicon.ico in the root directory -->

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">

        <meta name="theme-color" content="#fafafa">

        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>

        <script src="jsLoadImage/load-image.all.min.js"></script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <style>
            canvas {
                position: absolute;
                top: 0;
                left: 0;
            }
        </style>
    </head>

    <body>
        <!-- face-api.js -->
        <script src="js/face-api.min.js"></script>
        
                
        <div id="isConvert"></div>

        <!-- テストに使用する画像 -->
        <img id="img" src="face.jpg"></img>
        <canvas id="overlay"></canvas>
        <canvas width="100" height="100" id="sample" style="background-color:yellow;"></canvas>
        <h3>トリミング後</h3>
        <img id="selectImg"></img>
        

        ファイル：<input type="file" accept="image/jpeg,image/png,image/gif" onchange="fileup(this)" />
        
        
        </div>

        <script>
            //参考：https://tech-it.r-net.info/program/javascript/265/
            //
            // 画像の取得
            const img = document.getElementById('img')

            const fileup = (e) => {
                console.log(e)
                const img2 = document.getElementById('selectImg');
                const reader = new FileReader();
                const imgReader = new Image();
                reader.onloadend = () => {
                    imgReader.onload = () => {
                        const imgType = imgReader.src.substring(5, imgReader.src.indexOf(';'));
                        const canvas = document.createElement('canvas');
                        const ctx = canvas.getContext('2d');
                        canvas.width = imgReader.width;
                        canvas.height = imgReader.height;
                        ctx.drawImage(imgReader,0,0,imgReader.width,imgReader.height);
                        console.log(imgReader.width)
                        console.log(imgReader.height)
                        img2.src = canvas.toDataURL(imgType);
                    }
                    imgReader.src = reader.result;
                }
                reader.readAsDataURL(e.files[0]);
            }

            const app = async () => {
                // モデルの読み込み
                await faceapi.nets.tinyFaceDetector.load("models/");
                //document.getElementById('isConvert').innerText='顔検出中';



                // 顔検出の実行
                //const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
                const displaySize = { width: img.width, height: img.height }
                // resize the overlay canvas to the input dimensions
                const canvas = document.getElementById('overlay')
                faceapi.matchDimensions(canvas, displaySize)

                const startTime = Date.now(); // 開始時間
                
                /* Display detected face bounding boxes */
                //const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
                const detections = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
                const endTime = Date.now(); // 終了時間
                console.log(endTime - startTime); // 何ミリ秒かかったかを表示する
                //document.getElementById('isConvert').innerText='顔検出完了';
                // resize the detected boxes in case your displayed image has a different size than the original
                const resizedDetections = faceapi.resizeResults(detections, displaySize)
                console.log(resizedDetections)
                console.log(resizedDetections._box._height)
                console.log(resizedDetections._box._width)
                console.log(resizedDetections._box._x)
                console.log(resizedDetections._box._y)
                console.log(parseInt(resizedDetections._box._height))
                console.log(parseInt(resizedDetections._box._width))
                console.log(parseInt(resizedDetections._box._x))
                console.log(parseInt(resizedDetections._box._y))
                var h = parseInt(resizedDetections._box._height)
                var w = parseInt(resizedDetections._box._width)
                var x = parseInt(resizedDetections._box._x)
                var y = parseInt(resizedDetections._box._y)
                // draw detections into the canvas
                faceapi.draw.drawDetections(canvas, resizedDetections)
                var tensor = test(x,y,w,h)
                model=await tf.loadLayersModel('tfmodel/model.json')
                var prediction = await model.predict(tensor)
                console.log(prediction)
                // 結果の出力
                //console.log(detections);
                //const trimimg=document.getElementById('sample')
                //console.log(trimimg.width)
                //console.log(trimimg.height)
                console.log("Prediction ended.")
            }

            function test(x,y,w,h) {
                //描画コンテキストの取得
                var canvas = document.getElementById('sample');
                if (canvas.getContext) {
                    var context = canvas.getContext('2d');
                    //元イメージの座標(x, y)から幅w高さhの範囲を使用して、座標(10, 10)の位置に、サイズ200×50でイメージを表示
                    context.drawImage(img, x, y, w, h, 0, 0, 100, 100);
                }
                tensor_image=preprocessImage(canvas);
                return tensor_image;
            }

            function preprocessImage(image){
                let tensor = tf.browser.fromPixels(image).resizeNearestNeighbor([128,128]).toFloat();
                let offset = tf.scalar(255);
                return tensor.div(offset).expandDims();
            }
            
            app()
        </script>
    </body>
</html>
