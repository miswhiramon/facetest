<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title></title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <meta property="og:title" content="">
        <meta property="og:type" content="">
        <meta property="og:url" content="">
        <meta property="og:image" content="">

        <link rel="manifest" href="site.webmanifest">
        <link rel="apple-touch-icon" href="icon.png">
        <!-- Place favicon.ico in the root directory -->

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">

        <meta name="theme-color" content="#fafafa">

        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>

        <script src="jsLoadImage/load-image.all.min.js"></script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <style>
            canvas {
                position: absolute;
                top: 0;
                left: 0;
            }
        </style>
    </head>

    <body>
        <!-- face-api.js -->
        <script src="js/face-api.min.js"></script>
        
                
        <div id="isConvert"></div>

        <!-- テストに使用する画像 -->
        <img id="img" src="face.jpg"></img>
        
        <canvas width="100" height="100" id="sample" style="background-color:yellow;"></canvas>
        <canvas id="overlay"></canvas>
        <h3>トリミング後</h3>
        <img id="selectImg"></img>
        

        ファイル：<input type="file" accept="image/jpeg,image/png,image/gif" onchange="fileup(this)" />
        
        
        </div>

        <script>
            var prediction
            var transImage

            class InstanceNormalization extends tf.layers.Layer {
                static className = 'InstanceNormalization';
                constructor(config) {
                    super(config);
                    this.axis=config.axis;
                    this.epsilon=config.epsilon;
                    this.center=config.center;
                    this.scale=config.scale;
                    this.beta_initializer=config.beta_initializer;//'zeros';
                    this.gamma_initializer=config.gamma_initializer;//'ones';
                    this.beta_regularizer=config.beta_regularizer;
                    this.gamma_regularizer=config.gamma_regularizer;
                    this.beta_constraint=config.beta_constraint;
                    this.gamma_constraint=config.gamma_constraint;
                }

                build(inputShape) {
                    const ndim = inputShape.length;
                    console.log(inputShape)
                    console.log(ndim)

                    this.input_spec = tf.input({shape:ndim})
                    var shape;
                    if (this.axis==null){
                        //shape = (1,)
                        shape=tf.tensor([1])
                    }else{
                        //shape = (inputShape[this.axis],)
                        shape=tf.tensor([inputShape[this.axis]])
                    }
                    
                    if (this.scale){
                        this.gamma = this.addWeight('gamma',[],
                                                    'float32',
                                                    tf.initializers.ones())/*,
                                                    regularizer=this.gamma_regularizer,
                                                    constraint=this.gamma_constraint)*/
                    }else{
                        this.gamma=null;
                    }
                        

                    if (this.center){
                        this.beta = this.addWeight('beta',[],
                                                    'float32',
                                                    tf.initializers.zeros())/*,
                                                    regularizer=this.beta_regularizer,
                                                    constraint=this.beta_constraint)*/
                    }else{
                        this.beta = null;
                    }
                        
                    this.built = True
                }

                call(input) {
                    return tf.tidy(() => {
                        const input_shape = input.shape;
                        const reduction_axes = tf.range(1,input_shape.length,1);
                        //const reduction_axes = tf.range(0,input_shape.length,1);//list(range(0, len(input_shape)))

                        /*if (this.axis != null){
                            del reduction_axes[this.axis]
                        }*/

                        //del reduction_axes[0]

                        var mean = tf.mean(inputs, reduction_axes, keepDims=True)
                        var stddev = tf.moments(inputs, reduction_axes, keepDims=True).variance.sqrt() + this.epsilon
                        var normed = (inputs - mean) / stddev

                        broadcast_shape = tf.ones([input_shape.length]);//[1] * (input_shape.length)
                        if (this.axis != null){
                            broadcast_shape[this.axis] = input_shape[this.axis]
                        }                            

                        if (this.scale){
                            broadcast_gamma = tf.reshape(this.gamma, broadcast_shape)
                            normed = normed.mul(broadcast_gamma)
                        }
                            
                        if (this.center){
                            broadcast_beta = tf.reshape(this.beta, broadcast_shape)
                            normed = normed.mul(broadcast_beta)
                        }                            
                        return normed
                    });
                }

                getConfig() {
                    const config = super.getConfig();
                    return config;
                }

                /**
                 * The static className getter is required by the 
                 * registration step (see below).
                 */
                static get className() {
                    return 'InstanceNormalization';
                }
            }
            /**
             * Regsiter the custom layer, so TensorFlow.js knows what class constructor
             * to call when deserializing an saved instance of the custom layer.
             */
            tf.serialization.registerClass(InstanceNormalization);

            //参考：https://tech-it.r-net.info/program/javascript/265/
            //
            // 画像の取得
            const img = document.getElementById('img')

            const fileup = (e) => {
                console.log(e)
                const img2 = document.getElementById('img');
                const reader = new FileReader();
                const imgReader = new Image();
                reader.onloadend = () => {
                    imgReader.onload = () => {
                        const imgType = imgReader.src.substring(5, imgReader.src.indexOf(';'));
                        const canvas = document.createElement('canvas');
                        const ctx = canvas.getContext('2d');
                        canvas.width = imgReader.width;
                        canvas.height = imgReader.height;
                        ctx.drawImage(imgReader,0,0,imgReader.width,imgReader.height);
                        console.log(imgReader.width)
                        console.log(imgReader.height)
                        img2.src = canvas.toDataURL(imgType);
                    }
                    imgReader.src = reader.result;
                }
                reader.readAsDataURL(e.files[0]);
                app()
            }

            const app = async () => {
                // モデルの読み込み
                await faceapi.nets.tinyFaceDetector.load("models/");
                //document.getElementById('isConvert').innerText='顔検出中';



                // 顔検出の実行
                //const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
                const displaySize = { width: img.width, height: img.height }
                // resize the overlay canvas to the input dimensions
                const canvas = document.getElementById('overlay')
                faceapi.matchDimensions(canvas, displaySize)

                const startTime = Date.now(); // 開始時間
                
                /* Display detected face bounding boxes */
                //const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
                const detections = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
                const endTime = Date.now(); // 終了時間
                console.log(endTime - startTime); // 何ミリ秒かかったかを表示する
                //document.getElementById('isConvert').innerText='顔検出完了';
                // resize the detected boxes in case your displayed image has a different size than the original
                const resizedDetections = faceapi.resizeResults(detections, displaySize)
                console.log(resizedDetections)
                console.log(resizedDetections._box._height)
                console.log(resizedDetections._box._width)
                console.log(resizedDetections._box._x)
                console.log(resizedDetections._box._y)
                console.log(parseInt(resizedDetections._box._height))
                console.log(parseInt(resizedDetections._box._width))
                console.log(parseInt(resizedDetections._box._x))
                console.log(parseInt(resizedDetections._box._y))
                var h = parseInt(resizedDetections._box._height)
                var w = parseInt(resizedDetections._box._width)
                var x = parseInt(resizedDetections._box._x)
                var y = parseInt(resizedDetections._box._y)
                // draw detections into the canvas
                faceapi.draw.drawDetections(canvas, resizedDetections)
                var tensor = test(x,y,w,h)
                model=await tf.loadLayersModel('tfmodel/model.json')
                prediction = await model.predict(tensor)
                console.log(prediction.shape)
                
                console.log(prediction.unstack(0)[0])
                prediction=prediction.unstack(0)[0]
                let offset_mul = tf.scalar(127.5);
                let offset_add = tf.scalar(1);
                prediction=prediction.add(offset_add).mul(offset_mul);
                var image = prediction.clipByValue(0,255).toInt();     
                transImage = tf.browser.toPixels(image,canvas)
                
                //var result = document.getElementById('img');
                //result.src = transImage
                

                // 結果の出力
                //console.log(detections);
                //const trimimg=document.getElementById('sample')
                //console.log(trimimg.width)
                //console.log(trimimg.height)
                console.log("Prediction ended.")
            }

            function test(x,y,w,h) {
                //描画コンテキストの取得
                var canvas = document.getElementById('sample');
                if (canvas.getContext) {
                    var context = canvas.getContext('2d');
                    //元イメージの座標(x, y)から幅w高さhの範囲を使用して、座標(10, 10)の位置に、サイズ200×50でイメージを表示
                    context.drawImage(img, x, y, w, h, 0, 0, 100, 100);
                }
                tensor_image=preprocessImage(canvas);
                return tensor_image;
            }

            function preprocessImage(image){
                //このあたりの処理内容オフセット等を学習時と一致させる。
                let tensor = tf.browser.fromPixels(image).resizeNearestNeighbor([128,128]).toFloat();
                let offset_div = tf.scalar(127.5);
                let offset_sub = tf.scalar(1);
                return tensor.div(offset_div).sub(offset_sub).expandDims();
            }
            
        </script>
    </body>
</html>
