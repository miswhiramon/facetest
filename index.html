<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title></title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <meta property="og:title" content="">
        <meta property="og:type" content="">
        <meta property="og:url" content="">
        <meta property="og:image" content="">

        <link rel="manifest" href="site.webmanifest">
        <link rel="apple-touch-icon" href="icon.png">
        <!-- Place favicon.ico in the root directory -->

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">

        <meta name="theme-color" content="#fafafa">

        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>

        <script src="jsLoadImage/load-image.all.min.js"></script>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <style>
            canvas {
                position: absolute;
                top: 0;
                left: 0;
            }
        </style>
    </head>

    <body>
        <!-- face-api.js -->
        <script src="js/face-api.min.js"></script>
        
        
        
        <div id="isConvert"></div>

        <!-- テストに使用する画像 -->
        <img id="boundingbox" src="face_boundbox.jpg"></img>
        <img id="img" src="face.jpg"></img>        
        <canvas id="overlay"></canvas>

        <div id="file_upload" class="file-upload">
            <div id="prev" class="prev" data-file-image></div>
            <label class="imgfile btn" for="imgfile">
                <input class="imgfile__input" type="file" id="imgfile">
                <div class="imgfile__button">画像選択する</div>
            </label>
        </div>

        
        </div>

        <script>
            // 画像の取得
            const img = document.getElementById('img')

            $('#imgfile').on('change', function (e) {
                displayInputFilePreview(e)
            });
            
            function displayInputFilePreview(e) {
                const file = e.target.files[0];
                loadImage.parseMetaData(file, function (data) {
                    var options = {
                        maxHeight: 1024,
                        maxWidth: 1024,
                        canvas: true
                    };
                    if (data.exif) {
                        options.orientation = data.exif.get('Orientation');
                    }
                    loadImage(file, function (data) {
                        var dataUri = data.toDataURL('image/jpeg');
                        $('#prev')
                                .attr('data-file-image', dataUri)
                                .css('background-image', 'url(' + dataUri + ')');
                    }, options);
                });
            }

            

            const app = async () => {
                // モデルの読み込み
                await faceapi.nets.tinyFaceDetector.load("models/");
                //document.getElementById('isConvert').innerText='顔検出中';



                // 顔検出の実行
                //const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
                const displaySize = { width: img.width, height: img.height }
                // resize the overlay canvas to the input dimensions
                const canvas = document.getElementById('overlay')
                faceapi.matchDimensions(canvas, displaySize)

                const startTime = Date.now(); // 開始時間
                
                /* Display detected face bounding boxes */
                //const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
                const detections = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
                const endTime = Date.now(); // 終了時間
                console.log(endTime - startTime); // 何ミリ秒かかったかを表示する
                //document.getElementById('isConvert').innerText='顔検出完了';
                // resize the detected boxes in case your displayed image has a different size than the original
                const resizedDetections = faceapi.resizeResults(detections, displaySize)
                console.log(resizedDetections)
                console.log(resizedDetections._box._height)
                console.log(resizedDetections._box._width)
                console.log(resizedDetections._box._x)
                console.log(resizedDetections._box._y)
                console.log(parseInt(resizedDetections._box._height))
                console.log(parseInt(resizedDetections._box._width))
                console.log(parseInt(resizedDetections._box._x))
                console.log(parseInt(resizedDetections._box._y))
                // draw detections into the canvas
                faceapi.draw.drawDetections(canvas, resizedDetections)
                // 結果の出力
                console.log(detections);
            }
            
            app()
        </script>
    </body>
</html>
